{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f747e52e-95a1-4f0f-b714-6a0c3412c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a423f125-9e7d-44f5-85ce-f0eb60ec4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de44646b-77e6-485a-a568-6ff47cf11c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c93949b-1098-4ae5-9968-10da32c08cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97487307-677d-44a3-a614-0ff223968d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e58b3e5-82d5-4b6b-87f4-7609afef10b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
    "#!wget https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acb37cb5-6406-4411-b66f-292cfbeca9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = nlp.data.TSVDataset(\"train.tsv\", field_indices=[1,2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(\"val.tsv\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8518ed7-0867-44e9-93e4-c1df0eeaebfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cd5c5e-7730-45df-8d17-b0382b965ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80ce6c-5ef1-43f6-a053-92c9dd85929d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dee4aac7-7311-481b-89ad-89721960f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [transform([i[label_idx]]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + self.labels[i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab4819bd-ffdb-494c-8a7f-e47e6f7cc2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 32\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 300\n",
    "max_grad_norm = 1\n",
    "log_interval = 50\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "606e7ec3-033d-4e62-a249-789f4a2c7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a2d67db-da81-4023-953a-29d44d8915a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abae496f-e70a-431d-a5af-fa1e88b8c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #hidden = [batch size, src len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        \n",
    "        #energy = [batch size, src len, dec hid dim]\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        #attention= [batch size, src len]\n",
    "        \n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c06a7494-264e-4e6c-b443-393f55305c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTSeq2Seq(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert, attention,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTSeq2Seq, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "        \n",
    "        self.embed_size = 128                 \n",
    "        self.embedding = nn.Embedding(len(vocab), self.embed_size)\n",
    "        #self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        \n",
    "        self.attention = attention\n",
    "        \n",
    "        self.decoder = nn.GRU(self.embed_size + hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size * 2 + self.embed_size, len(vocab))\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids, output_ids, output_valid_lengths, teacher_forcing_ratio=0.5):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        sequence_output, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device), return_dict=False)\n",
    "        if self.dr_rate:\n",
    "            hidden = self.dropout(pooler)\n",
    "            \n",
    "        hidden = hidden                      \n",
    "            \n",
    "        output_id = output_ids[0,:]        \n",
    "        trg_len = output_ids.shape[0]\n",
    "        batch_size = output_ids.shape[1]\n",
    "        trg_vocab_size = len(vocab)\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(device)\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            sequence_output = sequence_output.permute(1, 0, 2)\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            \n",
    "            output_id_embedded = self.embedding(output_id.unsqueeze(0))\n",
    "            \n",
    "            a = self.attention(hidden, sequence_output)\n",
    "            \n",
    "            a = a.unsqueeze(1)\n",
    "        \n",
    "            #a = [batch size, 1, src len]\n",
    "\n",
    "            sequence_output = sequence_output.permute(1, 0, 2)\n",
    "\n",
    "            #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "\n",
    "            weighted = torch.bmm(a, sequence_output)\n",
    "\n",
    "            #weighted = [batch size, 1, enc hid dim * 2]\n",
    "\n",
    "            weighted = weighted.permute(1, 0, 2)\n",
    "\n",
    "            #weighted = [1, batch size, enc hid dim * 2]\n",
    "\n",
    "            rnn_input = torch.cat((output_id_embedded, weighted), dim = 2)\n",
    "            \n",
    "            \n",
    "            output, hidden = self.decoder(rnn_input, hidden.unsqueeze(0))\n",
    "            \n",
    "            assert (output == hidden).all()\n",
    "        \n",
    "            output_id_embedded = output_id_embedded.squeeze(0)\n",
    "            \n",
    "            hidden = hidden.squeeze(0)\n",
    "            output = output.squeeze(0)\n",
    "            weighted = weighted.squeeze(0)\n",
    "            \n",
    "\n",
    "            pred = self.out(torch.cat((output, weighted, output_id_embedded), dim = 1))\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = pred\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = pred.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            output_id = output_ids[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23547b38-789d-469c-93a9-1313b8b3e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = Attention(768, 768)\n",
    "model = BERTSeq2Seq(bertmodel, attn, dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "710175d7-7351-49d1-b477-3db305f50e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e2c0fd0-e355-4a0f-930d-7654c5298b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=vocab['[PAD]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7257155f-add7-43c0-9ebd-06cb18a43c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b375e3c2-91ce-4076-9423-e12e2be05ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2e4c9c4-06bd-41df-847d-be1e9fd08b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    \n",
    "    flatten_X = X.view(-1, out.shape[2])\n",
    "    flatten_Y = Y.flatten()\n",
    "    \n",
    "    max_vals, max_indices = torch.max(flatten_X, 1)    \n",
    "    \n",
    "    token_acc = (((max_indices == flatten_Y) * (flatten_Y.flatten() != 1)).sum().data.cpu().numpy())/ (flatten_Y.flatten() != 1).sum().data.cpu()\n",
    "    sentence_acc = ((X.transpose(1, 0).argmax(-1) != Y.transpose(1, 0)).sum(-1) == 0).float().mean()\n",
    "    \n",
    "    return token_acc, sentence_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21864cb0-f92e-41f5-963b-2b5e1646de79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7128e6191bf94c0eadd92ccf6eef7b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=219.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 8.995418548583984 train token acc 0.0 train sentence acc 0.0\n",
      "epoch 1 batch id 51 loss 8.953070640563965 train token acc 8.072692435234785e-05 train sentence acc 0.0\n",
      "epoch 1 batch id 101 loss 8.857170104980469 train token acc 0.001972799887880683 train sentence acc 0.0\n",
      "epoch 1 batch id 151 loss 8.562484741210938 train token acc 0.049735809252319844 train sentence acc 0.0\n",
      "epoch 1 batch id 201 loss 8.208989143371582 train token acc 0.09475679173416908 train sentence acc 0.0\n",
      "\n",
      "epoch 1 train token acc 0.10640598112795945 train sentence acc 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e96397112c24e8cbfebc74b79b98e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1 test token acc 0.23676670268383426 test sentence acc 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3531071c53e463c90b7c3cac7d5d798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=219.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 8.077078819274902 train token acc 0.22919937781989574 train sentence acc 0.0\n",
      "epoch 2 batch id 51 loss 7.966713905334473 train token acc 0.23417927586363957 train sentence acc 0.0\n"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_token_acc = 0.0\n",
    "    train_sentence_acc = 0.0\n",
    "    test_token_acc = 0.0\n",
    "    test_sentence_acc = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_id, (token_ids, valid_length, segment_ids, output_ids, output_valid_lengths, _) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "                       \n",
    "        label_ids = output_ids.transpose(1, 0).long().to(device)\n",
    "        \n",
    "        output_valid_lengths = output_valid_lengths\n",
    "        \n",
    "        out = model(token_ids, valid_length, segment_ids, label_ids, output_valid_lengths)        \n",
    "                \n",
    "        loss = loss_fn(out.view(-1, out.shape[2]), label_ids.flatten())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        \n",
    "        token_acc, sentence_acc = calc_accuracy(out, label_ids)\n",
    "        \n",
    "        train_token_acc += token_acc\n",
    "        train_sentence_acc += sentence_acc\n",
    "        \n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train token acc {} train sentence acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_token_acc / (batch_id+1), train_sentence_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train token acc {} train sentence acc {}\".format(e+1, train_token_acc / (batch_id+1), train_sentence_acc / (batch_id+1)))\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, output_ids, output_valid_lengths, _) in enumerate(tqdm(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "                       \n",
    "        label_ids = output_ids.transpose(1, 0).long().to(device)\n",
    "        \n",
    "        output_valid_lengths = output_valid_lengths\n",
    "        \n",
    "        out = model(token_ids, valid_length, segment_ids, label_ids, output_valid_lengths)        \n",
    "        \n",
    "        token_acc, sentence_acc = calc_accuracy(out, label_ids)\n",
    "        \n",
    "        test_token_acc += token_acc\n",
    "        test_sentence_acc += sentence_acc\n",
    "        \n",
    "    print(\"epoch {} test token acc {} test sentence acc {}\".format(e+1, test_token_acc / (batch_id+1), test_sentence_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf3b2d-e7f4-4ef1-bd7c-aa19b4213fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26536302-a103-4728-8b44-3cb298acb8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8770ff8-2d6e-4445-b4c5-913de63e2ec8",
   "metadata": {},
   "source": [
    "# Restore code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ecb33e-253e-4578-9903-292d0ef1eaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5716c-654b-45bb-907d-8dff14ed9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(input):\n",
    "    return ' '.join([vocab.idx_to_token[id] for id in input]).replace('[CLS]', '').replace('[PAD]', '').replace('[SEP]', '').replace(' ', '').replace('▁', ' ').strip().replace('= =', '==')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae6fec2-2111-4276-9977-23ce00b309ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_sentence(label_ids.transpose(0, 1)[-9]))\n",
    "\n",
    "print(generate_sentence(out.transpose(0, 1).argmax(-1)[:, 1:][-9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0982fff-7318-4d09-86b6-7712c08815c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(label_ids.flatten() != 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16960b-88ee-42f8-b7dd-cde85fdc590f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3301a5-7aeb-45b0-bbdc-b99ed6df592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809ca8f-4574-4c1a-b085-bbec8cc5c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.transpose(0, 1).argmax(-1)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e31a12-533b-4cd2-ad57-1fc578f9e50c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
